
# ğŸ§¬ Deepfake Detection Using rPPG & Deep Learning

A robust hybrid system that detects deepfake videos by analyzing **physiological signals (remote Photoplethysmography â€“ rPPG)** along with **deep learningâ€“based visual fake detection models**.  
This project merges **biological cues** with **frame-level CNN/Transformer predictions** to significantly improve deepfake detection reliability.

---

## Features

### ğŸ”¹ Physiological Signal Extraction
- Extract rPPG signals from green-channel variations.
- Estimate heart rate & signal stability.
- Identify physiological inconsistencies typical in deepfakes.

### ğŸ”¹ Deepfake Detection Models
- CNN-based frame-level classifier.
- Optional Transformer-based temporal analysis.
- Detects texture artifacts, blending issues, and motion inconsistencies.

### ğŸ”¹ Fusion Engine
- Combines visual predictions + physiological metrics.
- Increases robustness on unseen deepfake techniques.

### ğŸ”¹ End-to-End Automated Pipeline
- Input video â†’ Face Tracking â†’ rPPG Extraction â†’ CNN Prediction â†’ Final Decision.

---

## ğŸ— Project Structure

```

Deepfake_Detection_Project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ real/
â”‚   â”œâ”€â”€ fake/
â”‚   â””â”€â”€ samples/
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ rppg/
â”‚   â”œâ”€â”€ deepfake_cnn/
â”‚   â”œâ”€â”€ face_recognition/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚     â”œâ”€â”€ face_extraction.py
â”‚   â”‚     â”œâ”€â”€ frame_generator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ rppg/
â”‚   â”‚     â”œâ”€â”€ rppg_extractor.py
â”‚   â”‚     â”œâ”€â”€ heart_rate_estimator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ deepfake/
â”‚   â”‚     â”œâ”€â”€ cnn_detector.py
â”‚   â”‚     â”œâ”€â”€ transformer_detector.py
â”‚   â”‚
â”‚   â”œâ”€â”€ fusion/
â”‚   â”‚     â””â”€â”€ decision_fusion.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚         â”œâ”€â”€ video_utils.py
â”‚         â”œâ”€â”€ signal_utils.py
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```

---

## Installation & Setup

### 1ï¸âƒ£ Create virtual environment
```

python -m venv venv

```

### 2ï¸âƒ£ Activate environment
#### Windows:
```

venv\Scripts\activate

```
#### Mac/Linux:
```

source venv/bin/activate

```

### 3ï¸âƒ£ Install dependencies
```

pip install -r requirements.txt

```

---

## â–¶ï¸ Running the Project

To execute the full pipeline:

```

python main.py

```

This performs:
1. Face extraction  
2. rPPG heart rate estimation  
3. Deepfake probability prediction  
4. Final decision fusion  

---

## ğŸ”§ How the System Works

### **1. Face Detection & Preprocessing**
- Extracts face ROI using Haar Cascades or Mediapipe.
- Normalizes frames for rPPG and CNN input.

### **2. rPPG Signal Extraction**
- Computes the average green-channel intensity per frame.
- Converts the temporal waveform into an estimated heart rate.
- Deepfakes show unstable biological rhythms.

### **3. Deepfake Model Prediction**
- CNN analyzes texture, blending, edge inconsistencies.
- Optional Transformer model analyzes temporal coherence.

### **4. Fusion Layer**
Combines:
- Deepfake probability  
- Heart rate stability  
- Signal quality index  

Outputs **Real / Fake** classification.

---

## Recommended Datasets

### Deepfake datasets:
- FaceForensics++
- Celeb-DF
- DFDC
- DeepFake-TIMIT
- FakeAVCeleb

### Physiological datasets (optional):
- PURE
- VIPL-HR

---

## Future Enhancements
- Add micro-expression detection  
- Build Streamlit GUI  
- Deploy as cloud API  
- Add LSTM-based temporal fusion  
- Optimize for real-time inference  

---

## Contributing
Pull requests and suggestions are welcome!

